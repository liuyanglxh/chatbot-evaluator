# 对话完整性评估器 - 使用指南

## 📋 评估器简介

**评估器名称**: Conversation Completeness (对话完整性)

**评估框架**: DeepEval - GEval (自定义评估)

**评估目的**: 评估AI对话回答的完整性和质量

---

## 🎯 评估维度

对话完整性评估从三个维度综合评估回答质量：

### 1. 信息完整性（40%）

- ✅ 是否回答了用户问题的所有方面
- ✅ 是否提供了必要的关键信息
- ✅ 是否遗漏了重要细节

### 2. 逻辑连贯性（30%）

- ✅ 回答是否前后一致、逻辑清晰
- ✅ 论述是否有条理、层次分明
- ✅ 是否存在自相矛盾的内容

### 3. 内容充分性（30%）

- ✅ 解释是否充分、易于理解
- ✅ 是否提供了具体的例子或说明
- ✅ 是否避免了过于简略或含糊

---

## 📊 评分标准

| 分数范围 | 等级 | 描述 |
|---------|------|------|
| **0.0 - 0.2** | 1分 - 不完整 | 回答严重不完整，只回答了问题的很小一部分；缺少关键信息；逻辑混乱，前后矛盾 |
| **0.2 - 0.4** | 2分 - 较不完整 | 回答了部分问题，但遗漏重要信息；逻辑基本清楚，但不够连贯；内容不够充分 |
| **0.4 - 0.6** | 3分 - 中等完整 | 回答了问题的主要方面，但细节不够；逻辑基本清晰，偶有不连贯；内容基本充分 |
| **0.6 - 0.8** | 4分 - 较完整 | 回答了问题的大部分方面，细节较完整；逻辑清晰连贯；内容充分 |
| **0.8 - 1.0** | 5分 - 完整 | 全面回答了问题的所有方面；逻辑清晰严密；内容非常充分，解释详细 |

---

## 🚀 如何添加

### 方法1：通过界面添加

1. **打开主界面**
   ```bash
   cd evaluator_gui
   python main.py
   ```

2. **点击"添加评估器"按钮**

3. **填写信息**：
   - **评估器名称**: `对话完整性评估器`（或您喜欢的任何名称）
   - **评估框架**: `DeepEval`
   - **评估器类型**: `Conversation Completeness` ✅
   - **阈值**: `0.6`（推荐值）

4. **点击"添加"** → 完成！

### 方法2：直接使用

如果系统中已经有，直接在评估器列表中选择使用。

---

## 📝 测试数据要求

### 必需数据

```json
{
    "input": "用户的问题或对话",
    "actual_output": "AI的回答"
}
```

### 可选数据

```json
{
    "input": "用户的问题或对话",
    "actual_output": "AI的回答",
    "context": "相关上下文（可选）"
}
```

---

## 🧪 测试示例

### 示例1：完整回答（应该通过）

**问题**:
```
车险理赔需要准备哪些材料？整个流程是怎样的？
```

**回答**:
```
车险理赔需要准备以下材料：

1. 事故责任认定书 - 由交警部门出具
2. 维修发票 - 4S店或修理厂提供
3. 驾驶证和行驶证 - 复印件
4. 保险单 - 电子版或纸质版
5. 银行账户信息 - 用于接收赔款

理赔流程：
1. 发生事故后，立即报案给保险公司（48小时内）
2. 保护现场，等待交警处理
3. 收集上述理赔材料
4. 提交理赔申请（可以通过APP、网点或邮寄）
5. 保险公司审核（通常3-5个工作日）
6. 审核通过后，赔款打入指定账户

注意事项：
- 必须在事故发生后48小时内报案
- 所有材料需要提供原件或加盖公章的复印件
- 如果有人伤，还需要提供医疗证明和费用清单
```

**预期结果**: ✅ 通过 (得分 > 0.8)
- ✅ 全面回答了材料清单
- ✅ 详细说明了理赔流程
- ✅ 提供了注意事项
- ✅ 逻辑清晰，层次分明

### 示例2：不完整回答（可能失败）

**问题**:
```
车险理赔需要准备哪些材料？整个流程是怎样的？
```

**回答**:
```
理赔需要驾驶证和行驶证，到保险公司办理就行。
```

**预期结果**: ❌ 失败 (得分 < 0.4)
- ❌ 只回答了问题的很小一部分
- ❌ 遗漏了大部分材料
- ❌ 没有说明流程
- ❌ 内容过于简略

### 示例3：中等完整回答

**问题**:
```
车险理赔需要准备哪些材料？整个流程是怎样的？
```

**回答**:
```
车险理赔需要准备：事故认定书、维修发票、驾驶证行驶证、保单和银行账户。

流程是：先报案，然后准备材料，提交给保险公司审核，审核通过后赔款到账。
```

**预期结果**: 边缘 (0.4 - 0.6分)
- ✅ 列举了所需材料
- ⚠️ 说明了基本流程
- ⚠️ 但细节不够，缺少时间节点、注意事项
- ⚠️ 内容可以更详细

---

## 💡 适用场景

### ✅ 适合使用

1. **客服对话系统** - 评估客服是否完整回答客户问题
2. **知识问答系统** - 检查答案是否完整
3. **咨询对话** - 评估咨询建议是否充分
4. **多轮对话** - 检查对话的完整性和连贯性

### ❌ 不适合使用

1. **简单是非题** - 不需要复杂回答的问题
2. **单一信息查询** - 如"天气怎么样"
3. **简短确认** - 只需要简单确认的场景

---

## 🔧 技术实现

### 评估标准（部分）

```python
criteria = """评估对话回答的完整性和质量：

**评估维度：**

1. **信息完整性（40%）：**
   - 是否回答了用户问题的所有方面
   - 是否提供了必要的关键信息
   - 是否遗漏了重要细节

2. **逻辑连贯性（30%）：**
   - 回答是否前后一致、逻辑清晰
   - 论述是否有条理、层次分明
   - 是否存在自相矛盾的内容

3. **内容充分性（30%）：**
   - 解释是否充分、易于理解
   - 是否提供了具体的例子或说明
   - 是否避免了过于简略或含糊

...（完整标准见上文）
"""
```

### 评估参数

```python
evaluation_params = [
    LLMTestCaseParams.INPUT,      # 用户问题
    LLMTestCaseParams.ACTUAL_OUTPUT  # AI回答
]
```

### 执行评估

```python
from deepeval.metrics import GEval
from deepeval.test_case import LLMTestCase
from deepeval.test_case_params import LLMTestCaseParams

# 创建评估指标
metric = GEval(
    name="Conversation Completeness",
    criteria=criteria,
    evaluation_params=evaluation_params,
    threshold=0.6,
    model=model,
    verbose_mode=True,
    include_reason=True
)

# 创建测试用例
test_case = LLMTestCase(
    input="用户的问题",
    actual_output="AI的回答"
)

# 执行评估
result = metric.measure(test_case)
```

---

## 📈 评估结果解读

### 通过示例

**得分**: 0.85

**原因**:
```
The response comprehensively addresses all aspects of the user's question.
It provides a complete list of required documents, explains the claim process
in detail with clear steps, includes important notes and timeframes. The
response is well-organized, logically structured, and sufficiently detailed.
```

**中文翻译**:
```
该回答全面地解决了用户问题的所有方面。它提供了完整的所需文件清单，
详细说明了理赔流程，包含了清晰的步骤、重要说明和时间节点。回答组织良好，
逻辑结构清晰，内容详实。
```

### 失败示例

**得分**: 0.35

**原因**:
```
The response only addresses a small portion of the user's question. It
mentions only two documents and does not explain the claim process. The
response is too brief and lacks necessary details. Key information is missing.
```

**中文翻译**:
```
该回答只解决了用户问题的很小一部分。只提到了两种文件，没有说明理赔流程。
回答过于简略，缺少必要的细节。关键信息缺失。
```

---

## 🎯 最佳实践

### 1. 问题设计

**✅ 好的问题**（适合评估完整性）:
- "车险理赔需要准备哪些材料？流程是怎样的？"
- "请介绍一下重疾险的保障范围、等待期和免责条款。"
- "我想购买意外险，请告诉我保障内容、投保条件和理赔流程。"

**❌ 差的问题**（不适合）:
- "车险理赔要什么材料？"（太简单）
- "理赔多少钱？"（单一信息）

### 2. 阈值设置

- **严格**: 0.7 - 0.8（要求非常完整）
- **标准**: 0.6 - 0.7（推荐）
- **宽松**: 0.4 - 0.5（允许一定简化）

### 3. 优化建议

如果您的系统经常在这个评估中得分较低：

1. **增加回答长度** - 提供更多细节
2. **结构化回答** - 使用分点、分段
3. **补充注意事项** - 提供额外有用信息
4. **使用示例** - 通过例子说明

---

## 📝 快速开始

### 第一步：添加评估器

```bash
python main.py
```

1. 点击"添加评估器"
2. 填写信息：
   - 名称: `对话完整性`
   - 框架: `DeepEval`
   - 类型: `Conversation Completeness`
   - 阈值: `0.6`
3. 点击"添加"

### 第二步：准备测试数据

在"测试数据管理"中添加：

**名称**: `车险理赔完整回答`

**问题**:
```
车险理赔需要准备哪些材料？整个流程是怎样的？
```

**回答**:
```
车险理赔需要准备以下材料：
1. 事故责任认定书
2. 维修发票
3. 驾驶证和行驶证
4. 保险单
5. 银行账户信息

理赔流程：
1. 发生事故后48小时内报案
2. 保护现场，等待交警处理
3. 收集理赔材料
4. 提交理赔申请
5. 保险公司审核（3-5个工作日）
6. 赔款到账
```

### 第三步：执行评估

1. 点击"执行评估"
2. 选择"对话完整性"评估器
3. 选择测试数据
4. 点击"执行"

### 第四步：查看结果

评估完成后，您会看到：
- ✅ 完整性得分（0-1）
- ✅ 通过/失败状态
- ✅ 详细原因（中英对照）
- ✅ 评估维度分析

---

## ✅ 总结

**对话完整性评估器**已内置在系统中，使用DeepEval的GEval自定义实现。

**核心特点**:
- ✅ 三维度评估（信息、逻辑、内容）
- ✅ 5级评分标准
- ✅ 详细的评估原因
- ✅ 中英文对照显示

**适用场景**:
- 客服对话系统
- 知识问答
- 多轮对话
- 咨询建议

**下一步**: 添加评估器 → 准备测试数据 → 执行评估 → 查看结果

---

**文档时间**: 2025-01-22
**评估器**: Conversation Completeness (对话完整性)
**框架**: DeepEval - GEval
**状态**: ✅ 已内置，可直接使用
